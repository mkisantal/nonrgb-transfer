{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0, 1, 2, 3\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "from math import pi\n",
    "from copy import copy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'test_runs02/000_double_layer_very_narrow'\n",
    "model_name = 'resnet50'\n",
    "batch_size = 256\n",
    "epochs = 20\n",
    "debug = False\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_split = 0.8\n",
    "\n",
    "\n",
    "# validation_split = .2\n",
    "# shuffle_dataset = True\n",
    "# random_seed= 42\n",
    "# https://stackoverflow.com/questions/50544730/split-dataset-train-and-test-in-pytorch-using-custom-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.plot(np.array(history['loss'])[::2], label='loss1')\n",
    "    ax.plot(np.array(history['loss'])[1::2], label='loss1')\n",
    "    ax.plot(history['accuracy'], label='accuracy')\n",
    "    fig.legend(loc=2,  title=\"Training\")\n",
    "    fig.show()\n",
    "    ax.grid(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(run_name):\n",
    "    os.makedirs(run_name)\n",
    "    \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "#         transforms.ColorJitter(brightness=.2, contrast=0.2, saturation=0.2, hue=0),\n",
    "#         transforms.RandomAffine(degrees=[-45,45], translate=None, scale=[.8, 1.2], shear=None),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "root = '/home/mate/dataset/EuroSatRGB/images'\n",
    "full_dataset = datasets.ImageFolder(root, transform=data_transforms['test']) # does not support augmentation yet\n",
    "train_size = int(train_split * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "dataset_sizes = {'train': train_size, 'test': test_size}\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataset.dataset = copy(full_dataset)\n",
    "train_dataset.transforms = data_transforms['train']\n",
    "\n",
    "\n",
    "image_datasets = {'train': train_dataset,\n",
    "                  'test': test_dataset}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=8)\n",
    "              for x in ['train', 'test']}\n",
    "\n",
    "#------\n",
    "# image_datasets = {x: datasets.ImageFolder(root, transform=data_transforms[x])\n",
    "#                   for x in ['train', 'test']}\n",
    "\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "\n",
    "# indices = {x: list(range(dataset_sizes[x])) for x in ['train', 'test']}\n",
    "\n",
    "# split = int(np.floor(validation_split * dataset_sizes['test']))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(42)\n",
    "#     np.random.shuffle(indices)\n",
    "# train_indices, val_indices = indices['train'][split:], indices['test'][:split]\n",
    "\n",
    "# # Creating PT data samplers and loaders:\n",
    "# train_sampler = SubsetRandomSampler(train_indices)\n",
    "# valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler,\n",
    "                num_epochs=25):\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    history = {'loss': [],\n",
    "               'accuracy': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        output = (outputs>0.5).float()\n",
    "                        number_of_corrects = (output.argmax(dim=1) == labels).float().sum()\n",
    "                        running_corrects += number_of_corrects\n",
    "                        \n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                if debug:\n",
    "                    break\n",
    "            \n",
    "            epoch_loss = float(running_loss / dataset_sizes[phase]) \n",
    "            history['loss'].append(epoch_loss)\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            if phase == 'test':\n",
    "                epoch_accuracy = float(running_corrects / dataset_sizes[phase])\n",
    "                history['accuracy'].append(epoch_accuracy)\n",
    "                print('{} Accuracy: {:.4f}'.format(phase, epoch_accuracy))\n",
    "                with open(os.path.join(run_name, 'history.json'), 'w') as fout:\n",
    "                    json.dump(history, fout)\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            if not debug:\n",
    "                torch.save(model, os.path.join(run_name, model_name + '_{}.pth'.format(epoch)))\n",
    "    \n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    \n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = feature_extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_name == 'resnet18':\n",
    "#     model_ft = models.resnet18(pretrained=True)\n",
    "# elif model_name == 'resnet50':\n",
    "#     model_ft = models.resnet50(pretrained=True)\n",
    "# elif model_name == 'resnet152':\n",
    "#     model_ft = models.resnet152(pretrained=True)\n",
    "# else:\n",
    "#     raise ValueError('Unknown torchvision model name.')\n",
    "\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer(nn.Module):\n",
    "    def __init__(self, features_in, hidden=1024):\n",
    "        super(Multilayer, self).__init__()\n",
    "        self.layer1 = nn.Linear(features_in, hidden)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(hidden, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "#         x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = Multilayer(num_ftrs, hidden=10)\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_ft = nn.DataParallel(model_ft)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-4)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameter_requires_grad(model_ft, True)\n",
    "optimizer_ft = torch.optim.Adam(model_ft.parameters(), lr=1e-5)\n",
    "history2, model_ft2 = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
